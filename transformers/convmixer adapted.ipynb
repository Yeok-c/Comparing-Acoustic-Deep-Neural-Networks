{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tqbIKaMPLRw"
      },
      "source": [
        "# Image classification with ConvMixer\n",
        "\n",
        "**Author:** [Sayak Paul](https://twitter.com/RisingSayak)<br>\n",
        "**Date created:** 2021/10/12<br>\n",
        "**Last modified:** 2021/10/12<br>\n",
        "**Description:** An all-convolutional network applied to patches of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtKPcsVTPLR0"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Vision Transformers (ViT; [Dosovitskiy et al.](https://arxiv.org/abs/1612.00593)) extract\n",
        "small patches from the input images, linearly project them, and then apply the\n",
        "Transformer ([Vaswani et al.](https://arxiv.org/abs/1706.03762)) blocks. The application\n",
        "of ViTs to image recognition tasks is quickly becoming a promising area of research,\n",
        "because ViTs eliminate the need to have strong inductive biases (such as convolutions) for\n",
        "modeling locality. This presents them as a general computation primititive capable of\n",
        "learning just from the training data with as minimal inductive priors as possible. ViTs\n",
        "yield great downstream performance when trained with proper regularization, data\n",
        "augmentation, and relatively large datasets.\n",
        "\n",
        "In the [Patches Are All You Need](https://openreview.net/pdf?id=TVHS5Y4dNvM) paper (note: at\n",
        "the time of writing, it is a submission to the ICLR 2022 conference), the authors extend\n",
        "the idea of using patches to train an all-convolutional network and demonstrate\n",
        "competitive results. Their architecture namely **ConvMixer** uses recipes from the recent\n",
        "isotrophic architectures like ViT, MLP-Mixer\n",
        "([Tolstikhin et al.](https://arxiv.org/abs/2105.01601)), such as using the same\n",
        "depth and resolution across different layers in the network, residual connections,\n",
        "and so on.\n",
        "\n",
        "In this example, we will implement the ConvMixer model and demonstrate its performance on\n",
        "the CIFAR-10 dataset.\n",
        "\n",
        "To use the AdamW optimizer, we need to install TensorFlow Addons:\n",
        "\n",
        "```shell\n",
        "pip install -U -q tensorflow-addons\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SghHlQrPLR1"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP04KXBcPLR1",
        "outputId": "a76f34c4-8fb5-4ec6-db16-4a7b1a8163bf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HoOSB3YPLR2"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "To keep run time short, we will train the model for only 10 epochs. To focus on\n",
        "the core ideas of ConvMixer, we will not use other training-specific elements like\n",
        "RandAugment ([Cubuk et al.](https://arxiv.org/abs/1909.13719)). If you are interested in\n",
        "learning more about those details, please refer to the\n",
        "[original paper](https://openreview.net/pdf?id=TVHS5Y4dNvM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9SAgyDoVPLR3"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yysj4YuUPLR3"
      },
      "source": [
        "## Load the CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HvwjYLwYPLR4"
      },
      "outputs": [],
      "source": [
        "# (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "# val_split = 0.1\n",
        "\n",
        "# val_indices = int(len(x_train) * val_split)\n",
        "# new_x_train, new_y_train = x_train[val_indices:], y_train[val_indices:]\n",
        "# x_val, y_val = x_train[:val_indices], y_train[:val_indices]\n",
        "\n",
        "# print(f\"Training data samples: {len(new_x_train)}\")\n",
        "# print(f\"Validation data samples: {len(x_val)}\")\n",
        "# print(f\"Test data samples: {len(x_test)}\")\n",
        "\n",
        "# image_size = 32\n",
        "# auto = tf.data.AUTOTUNE\n",
        "\n",
        "# data_augmentation = keras.Sequential(\n",
        "#     [layers.RandomCrop(image_size, image_size), layers.RandomFlip(\"horizontal\"),],\n",
        "#     name=\"data_augmentation\",\n",
        "# )\n",
        "\n",
        "# def make_datasets(images, labels, is_train=False):\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "#     if is_train:\n",
        "#         dataset = dataset.shuffle(batch_size * 10)\n",
        "#     dataset = dataset.batch(batch_size)\n",
        "#     if is_train:\n",
        "#         dataset = dataset.map(\n",
        "#             lambda x, y: (data_augmentation(x), y), num_parallel_calls=auto\n",
        "#         )\n",
        "#     return dataset.prefetch(auto)\n",
        "\n",
        "\n",
        "# train_dataset = make_datasets(new_x_train, new_y_train, is_train=True)\n",
        "# val_dataset = make_datasets(x_val, y_val)\n",
        "# test_dataset = make_datasets(x_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpxi7LbiPLR5"
      },
      "source": [
        "## Prepare `tf.data.Dataset` objects\n",
        "\n",
        "Our data augmentation pipeline is different from what the authors used for the CIFAR-10\n",
        "dataset, which is fine for the purpose of the example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pGKZuxfFPLR5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files in Class_00_Modified_car_engines: 4644\n",
            "Number of files in Class_01_Regular_Vehicles: 9539\n",
            "Number of files in Class_02_Tools_and_Mechanisms: 13307\n",
            "Number of files in Class_03_Environmental_Sounds: 10488\n",
            "Number of files:  37978\n",
            "classes: ['Class_00_Modified_car_engines', 'Class_01_Regular_Vehicles', 'Class_02_Tools_and_Mechanisms', 'Class_03_Environmental_Sounds'], num_classes: 4\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os, sys, glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import random\n",
        "import datetime\n",
        "\n",
        "\n",
        "DATETIME_NOW = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "SEED = 42\n",
        "MODEL_NAME = 'Convmixer'\n",
        "FILE_RATIO = 0.2\n",
        "PATCH_HOP_DISTANCE = 1.05\n",
        "DATASET_DIR = \"../datasets/cer_dataset_16k_resampled_split/\"\n",
        "\n",
        "\n",
        "sys.path.append('../src')\n",
        "sys.path.append('../src/models')\n",
        "from models.get_models import get_model\n",
        "import models.yamnet_tf2.params as params\n",
        "params = params.Params(sample_rate=16000, patch_hop_seconds=PATCH_HOP_DISTANCE) # 0.25\n",
        "\n",
        "# from dataload_utils.data_load import get_dataset, get_filenames_and_classnames_list\n",
        "import dataload_utils.data_load as data_load\n",
        "from dataload_utils.data_aug import mix_up\n",
        "\n",
        "\n",
        "# SEED = 42\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# parent_dir = \"C:\\\\Users\\\\User\\\\Documents\\\\cer_dataset_16k_flattened_resampled\\\\\"\n",
        "dataset_loader = data_load.Dataset_loader(DATASET_DIR, params)\n",
        "filenames_all = dataset_loader.__filenames_all__\n",
        "classes = dataset_loader.__classes__\n",
        "num_classes = dataset_loader.__num_classes__\n",
        "print(\"classes: {}, num_classes: {}\".format(classes, num_classes))\n",
        "\n",
        "# To do real shuffling\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size=16\n",
        "random.shuffle(filenames_all)\n",
        "filenames_all=filenames_all[:int(len(filenames_all)*FILE_RATIO)]\n",
        "filenames_train = filenames_all[:int(len(filenames_all)*0.7)]\n",
        "filenames_eval = filenames_all[int(len(filenames_all)*0.7):int(len(filenames_all)*0.9)]\n",
        "filenames_test = filenames_all[int(len(filenames_all)*0.9):]\n",
        "\n",
        "@tf.function\n",
        "def resize_image(x):\n",
        "    x.set_shape([96, 64, 1])\n",
        "    return tf.image.resize(x, [96, 64])\n",
        "\n",
        "# Training set preparation\n",
        "train_dataset =  dataset_loader.get_dataset(filenames_train, augment=True).map(\n",
        "    map_func = lambda x, y: (resize_image(x), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "eval_dataset = dataset_loader.get_dataset(filenames_eval, augment=False).map(\n",
        "    map_func = lambda x, y: (resize_image(x), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "test_dataset = dataset_loader.get_dataset(filenames_test, augment=False).map(\n",
        "    map_func = lambda x, y: (resize_image(x), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "test_dataset = test_dataset\n",
        "\n",
        "train_dataset = train_dataset.shuffle(batch_size*2).batch(batch_size).cache().prefetch(AUTOTUNE)\n",
        "eval_dataset = eval_dataset.cache().shuffle(batch_size*2).batch(batch_size).prefetch(AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().shuffle(batch_size*2).batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "# Paths\n",
        "training_path = \"./training/{}\".format(DATETIME_NOW)\n",
        "\n",
        "model_training_path = training_path + \"/{}\".format(MODEL_NAME)\n",
        "ckp_path = model_training_path + \"/checkpoints/cp.ckpt\"\n",
        "log_path = model_training_path + \"/logs/fit\"    \n",
        "hd5_path = model_training_path + \"/model.hd5\"\n",
        "cfm_path = model_training_path + \"/confusion_matrix.png\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<ParallelMapDataset element_spec=(TensorSpec(shape=(96, 64, 1), dtype=tf.float32, name=None), TensorSpec(shape=(4,), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset =  dataset_loader.get_dataset(filenames_train, augment=True)\n",
        "train_dataset =  train_dataset.map(\n",
        "    map_func = lambda x, y: (resize_image(x), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anulo4CYPLR6"
      },
      "source": [
        "## ConvMixer utilities\n",
        "\n",
        "The following figure (taken from the original paper) depicts the ConvMixer model:\n",
        "\n",
        "![](https://i.imgur.com/yF8actg.png)\n",
        "\n",
        "ConvMixer is very similar to the MLP-Mixer, model with the following key\n",
        "differences:\n",
        "\n",
        "* Instead of using fully-connected layers, it uses standard convolution layers.\n",
        "* Instead of LayerNorm (which is typical for ViTs and MLP-Mixers), it uses BatchNorm.\n",
        "\n",
        "Two types of convolution layers are used in ConvMixer. **(1)**: Depthwise convolutions,\n",
        "for mixing spatial locations of the images, **(2)**: Pointwise convolutions (which follow\n",
        "the depthwise convolutions), for mixing channel-wise information across the patches.\n",
        "Another keypoint is the use of *larger kernel sizes* to allow a larger receptive field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jpglQyXAPLR7"
      },
      "outputs": [],
      "source": [
        "def activation_block(x):\n",
        "    x = layers.Activation(\"gelu\")(x)\n",
        "    return layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "def conv_stem(x, filters: int, patch_size: int):\n",
        "    x = layers.Conv2D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
        "    return activation_block(x)\n",
        "\n",
        "\n",
        "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
        "    # Depthwise convolution.\n",
        "    x0 = x\n",
        "    x = layers.DepthwiseConv2D(kernel_size=kernel_size, padding=\"same\")(x)\n",
        "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
        "\n",
        "    # Pointwise convolution.\n",
        "    x = layers.Conv2D(filters, kernel_size=1)(x)\n",
        "    x = activation_block(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_conv_mixer_256_8(\n",
        "    image_size=(96, 64, 1), filters=256, depth=8, kernel_size=5, patch_size=2, num_classes=4\n",
        "):\n",
        "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
        "    The hyperparameter values are taken from the paper.\n",
        "    \"\"\"\n",
        "    inputs = keras.Input((image_size))\n",
        "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
        "\n",
        "    # Extract patch embeddings.\n",
        "    x = conv_stem(x, filters, patch_size)\n",
        "\n",
        "    # ConvMixer blocks.\n",
        "    for _ in range(depth):\n",
        "        x = conv_mixer_block(x, filters, kernel_size)\n",
        "\n",
        "    # Classification block.\n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJvpiGcGPLR8"
      },
      "source": [
        "The model used in this experiment is termed as **ConvMixer-256/8** where 256 denotes the\n",
        "number of channels and 8 denotes the depth. The resulting model only has 0.8 million\n",
        "parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSKVKf5rPLR8"
      },
      "source": [
        "## Model training and evaluation utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LxMepZzvPLR9"
      },
      "outputs": [],
      "source": [
        "# Code reference:\n",
        "# https://keras.io/examples/vision/image_classification_with_vision_transformer/.\n",
        "\n",
        "\n",
        "def run_experiment(model):\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        checkpoint_filepath,\n",
        "        monitor=\"val_accuracy\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=eval_dataset,\n",
        "        epochs=num_epochs,\n",
        "        callbacks=[checkpoint_callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy = model.evaluate(test_dataset)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 96, 64, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " rescaling_2 (Rescaling)        (None, 96, 64, 1)    0           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 48, 32, 256)  1280        ['rescaling_2[0][0]']            \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 48, 32, 256)  0           ['conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 48, 32, 256)  1024       ['activation_34[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_34[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_16[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 48, 32, 256)  1024       ['activation_35[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_35[0][0]', \n",
            "                                                                  'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 48, 32, 256)  65792       ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 48, 32, 256)  0           ['conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 48, 32, 256)  1024       ['activation_36[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_17 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_36[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 48, 32, 256)  1024       ['activation_37[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_37[0][0]', \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 48, 32, 256)  65792       ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 48, 32, 256)  0           ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 48, 32, 256)  1024       ['activation_38[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_18 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_38[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_18[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 48, 32, 256)  1024       ['activation_39[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 48, 32, 256)  65792       ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 48, 32, 256)  0           ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 48, 32, 256)  1024       ['activation_40[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_19 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_40[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_19[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 48, 32, 256)  1024       ['activation_41[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_41[0][0]', \n",
            "                                                                  'batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 48, 32, 256)  65792       ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 48, 32, 256)  0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 48, 32, 256)  1024       ['activation_42[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_20 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_42[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_20[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 48, 32, 256)  1024       ['activation_43[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_43[0][0]', \n",
            "                                                                  'batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 48, 32, 256)  65792       ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 48, 32, 256)  0           ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 48, 32, 256)  1024       ['activation_44[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_21 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_44[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 48, 32, 256)  1024       ['activation_45[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 48, 32, 256)  65792       ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 48, 32, 256)  0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 48, 32, 256)  1024       ['activation_46[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_22 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_46[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_22[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 48, 32, 256)  1024       ['activation_47[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_47[0][0]', \n",
            "                                                                  'batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 48, 32, 256)  65792       ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 48, 32, 256)  0           ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 48, 32, 256)  1024       ['activation_48[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " depthwise_conv2d_23 (Depthwise  (None, 48, 32, 256)  6656       ['batch_normalization_48[0][0]'] \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 48, 32, 256)  0           ['depthwise_conv2d_23[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 48, 32, 256)  1024       ['activation_49[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 48, 32, 256)  0           ['batch_normalization_49[0][0]', \n",
            "                                                                  'batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 48, 32, 256)  65792       ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 48, 32, 256)  0           ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 48, 32, 256)  1024       ['activation_50[0][0]']          \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2 (Gl  (None, 256)         0           ['batch_normalization_50[0][0]'] \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4)            1028        ['global_average_pooling2d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 599,300\n",
            "Trainable params: 590,596\n",
            "Non-trainable params: 8,704\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "conv_mixer_model = get_conv_mixer_256_8()\n",
        "conv_mixer_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CPBEPegPLR9"
      },
      "source": [
        "## Train and evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6crtjm3zPLR9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "      9/Unknown - 14s 506ms/step - loss: 1.4130 - accuracy: 0.4097"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11248\\2995839918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_mixer_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_mixer_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11248\\4165521999.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     history = model.fit(\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1106\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 563\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 914\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m       \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m     \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \"\"\"\n\u001b[0;32m   1222\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\usc39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1187\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history, conv_mixer_model = run_experiment(conv_mixer_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmcYpnjbPLR9"
      },
      "source": [
        "The gap in training and validation performance can be mitigated by using additional\n",
        "regularization techniques. Nevertheless, being able to get to ~83% accuracy within 10\n",
        "epochs with 0.8 million parameters is a strong result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10E9WXotPLR-"
      },
      "source": [
        "## Visualizing the internals of ConvMixer\n",
        "\n",
        "We can visualize the patch embeddings and the learned convolution filters. Recall\n",
        "that each patch embedding and intermediate feature map have the same number of channels\n",
        "(256 in this case). This will make our visualization utility easier to implement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvF94Jw8PLR-"
      },
      "outputs": [],
      "source": [
        "# Code reference: https://bit.ly/3awIRbP.\n",
        "\n",
        "\n",
        "def visualization_plot(weights, idx=1):\n",
        "    # First, apply min-max normalization to the\n",
        "    # given weights to avoid isotrophic scaling.\n",
        "    p_min, p_max = weights.min(), weights.max()\n",
        "    weights = (weights - p_min) / (p_max - p_min)\n",
        "\n",
        "    # Visualize all the filters.\n",
        "    num_filters = 256\n",
        "    plt.figure(figsize=(8, 8))\n",
        "\n",
        "    for i in range(num_filters):\n",
        "        current_weight = weights[:, :, :, i]\n",
        "        if current_weight.shape[-1] == 1:\n",
        "            current_weight = current_weight.squeeze()\n",
        "        ax = plt.subplot(16, 16, idx)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        plt.imshow(current_weight)\n",
        "        idx += 1\n",
        "\n",
        "\n",
        "# We first visualize the learned patch embeddings.\n",
        "patch_embeddings = conv_mixer_model.layers[2].get_weights()[0]\n",
        "visualization_plot(patch_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogH-QK7ePLR-"
      },
      "source": [
        "Even though we did not train the network to convergence, we can notice that different\n",
        "patches show different patterns. Some share similarity with others while some are very\n",
        "different. These visualizations are more salient with larger image sizes.\n",
        "\n",
        "Similarly, we can visualize the raw convolution kernels. This can help us understand\n",
        "the patterns to which a given kernel is receptive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsYAwYtNPLR-"
      },
      "outputs": [],
      "source": [
        "# First, print the indices of the convolution layers that are not\n",
        "# pointwise convolutions.\n",
        "for i, layer in enumerate(conv_mixer_model.layers):\n",
        "    if isinstance(layer, layers.DepthwiseConv2D):\n",
        "        if layer.get_config()[\"kernel_size\"] == (5, 5):\n",
        "            print(i, layer)\n",
        "\n",
        "idx = 26  # Taking a kernel from the middle of the network.\n",
        "\n",
        "kernel = conv_mixer_model.layers[idx].get_weights()[0]\n",
        "kernel = np.expand_dims(kernel.squeeze(), axis=2)\n",
        "visualization_plot(kernel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whwu5qr4PLR-"
      },
      "source": [
        "We see that different filters in the kernel have different locality spans, and this pattern\n",
        "is likely to evolve with more training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAoxM8NBPLR_"
      },
      "source": [
        "## Final notes\n",
        "\n",
        "There's been a recent trend on fusing convolutions with other data-agnostic operations\n",
        "like self-attention. Following works are along this line of research:\n",
        "\n",
        "* ConViT ([d'Ascoli et al.](https://arxiv.org/abs/2103.10697))\n",
        "* CCT ([Hassani et al.](https://arxiv.org/abs/2104.05704))\n",
        "* CoAtNet ([Dai et al.](https://arxiv.org/abs/2106.04803))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "convmixer",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
